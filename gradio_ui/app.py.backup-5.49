#!/usr/bin/env python3
"""
Qwen Dev CLI - Championship Gradio UI

Vercel/Linear-inspired minimal clean design with real-time streaming.
Built for the MCP Hackathon with 27+ production tools.
"""

from __future__ import annotations

import os
import time
import uuid
from pathlib import Path
from typing import Any, Dict, List, Optional

import gradio as gr
import pandas as pd

from .cli_bridge import CLIStreamBridge
from .heroic_theme import create_heroic_theme

PROJECT_ROOT = Path.cwd()
CSS_PATH = Path(__file__).parent / "static" / "custom.css"

# Load CSS content as string
with open(CSS_PATH, 'r') as f:
    CUSTOM_CSS = f.read()

# Initialize CLI bridge
_bridge = CLIStreamBridge()

# --- DATA & HELPERS ---

COMMAND_EXAMPLES = [
    ["Read README.md and summarize setup"],
    ["Scan tests/ for flaky tests"],
    ["List qwen_dev_cli/tools"],
    ["Show git status & risky files"],
    ["Search for TODOs in repo"],
]

def _format_shell_output(text: str) -> str:
    """Format shell output for display in the code block."""
    if not text:
        return "Ready for commands..."
    return text

def _blank_metrics() -> Dict[str, Any]:
    return {
        "chunks": 0,
        "chars": 0,
        "sec": 0,
        "backend": _bridge.backend_label,
    }

def _get_mcp_tools_df() -> pd.DataFrame:
    """Get real MCP tools from ToolRegistry as DataFrame."""
    try:
        # Import tool classes
        from qwen_dev_cli.tools.base import ToolRegistry
        from qwen_dev_cli.tools.file_ops import (
            ReadFileTool, WriteFileTool, EditFileTool,
            ListDirectoryTool, DeleteFileTool
        )
        from qwen_dev_cli.tools.file_mgmt import (
            MoveFileTool, CopyFileTool, CreateDirectoryTool,
            ReadMultipleFilesTool, InsertLinesTool
        )
        from qwen_dev_cli.tools.search import SearchFilesTool, GetDirectoryTreeTool
        from qwen_dev_cli.tools.exec import BashCommandTool
        from qwen_dev_cli.tools.git_ops import GitStatusTool, GitDiffTool
        from qwen_dev_cli.tools.context import GetContextTool, SaveSessionTool, RestoreBackupTool
        from qwen_dev_cli.tools.terminal import (
            CdTool, LsTool, PwdTool, MkdirTool, RmTool,
            CpTool, MvTool, TouchTool, CatTool
        )
        
        # Instantiate registry and register all tools
        registry = ToolRegistry()
        
        # File Operations (10 tools)
        file_ops = [
            ReadFileTool(), WriteFileTool(), EditFileTool(),
            ListDirectoryTool(), DeleteFileTool(), MoveFileTool(),
            CopyFileTool(), CreateDirectoryTool(), ReadMultipleFilesTool(),
            InsertLinesTool()
        ]
        
        # Search & Navigation (2 tools)
        search_tools = [SearchFilesTool(), GetDirectoryTreeTool()]
        
        # Execution (1 tool)
        exec_tools = [BashCommandTool()]
        
        # Git Operations (2 tools)
        git_tools = [GitStatusTool(), GitDiffTool()]
        
        # Context Management (3 tools)
        context_tools = [GetContextTool(), SaveSessionTool(), RestoreBackupTool()]
        
        # Terminal Commands (9 tools)
        terminal_tools = [
            CdTool(), LsTool(), PwdTool(), MkdirTool(), RmTool(),
            CpTool(), MvTool(), TouchTool(), CatTool()
        ]
        
        # Build data list
        data = []
        
        for tool in file_ops:
            data.append({
                "Category": "File Operations",
                "Tool": tool.name,
                "Description": tool.description[:60] + "..." if len(tool.description) > 60 else tool.description
            })
        
        for tool in search_tools:
            data.append({
                "Category": "Search & Navigation",
                "Tool": tool.name,
                "Description": tool.description[:60] + "..." if len(tool.description) > 60 else tool.description
            })
        
        for tool in exec_tools:
            data.append({
                "Category": "Execution",
                "Tool": tool.name,
                "Description": tool.description[:60] + "..." if len(tool.description) > 60 else tool.description
            })
        
        for tool in git_tools:
            data.append({
                "Category": "Git Operations",
                "Tool": tool.name,
                "Description": tool.description[:60] + "..." if len(tool.description) > 60 else tool.description
            })
        
        for tool in context_tools:
            data.append({
                "Category": "Context Management",
                "Tool": tool.name,
                "Description": tool.description[:60] + "..." if len(tool.description) > 60 else tool.description
            })
        
        for tool in terminal_tools:
            data.append({
                "Category": "Terminal Commands",
                "Tool": tool.name,
                "Description": tool.description[:60] + "..." if len(tool.description) > 60 else tool.description
            })
        
        return pd.DataFrame(data)
    
    except Exception as e:
        # Fallback to minimal data if imports fail
        print(f"Warning: Could not load real tools: {e}")
        data = [
            {"Category": "File Operations", "Tool": "read_file", "Description": "Read file contents"},
            {"Category": "File Operations", "Tool": "write_file", "Description": "Write content to file"},
            {"Category": "Terminal", "Tool": "bash", "Description": "Execute shell commands"},
        ]
        return pd.DataFrame(data)

# --- CORE LOGIC ---

async def stream_conversation(
    message: str,
    history: List[Dict[str, Any]],
    session_id: str,
):
    """Stream output from CLI backend with visual states."""
    if not message.strip():
        yield history, "", session_id, _blank_metrics(), gr.update(visible=True)
        return

    # Initialize session
    session_value = session_id or f"session-{uuid.uuid4().hex[:8]}"
    
    # Update history with user message
    history = history or []
    history.append({"role": "user", "content": message})
    
    # PHASE 1: Thinking state with pulse animation
    history.append({"role": "assistant", "content": '<div class="thinking">‚è≥ Analyzing request...</div>'})
    terminal_output = "# Starting execution...\n"
    
    yield history, terminal_output, session_value, _blank_metrics(), gr.update(visible=False)

    start = time.monotonic()
    live_text = ""
    chunk_count = 0
    tool_log = []
    
    try:
        # PHASE 2: Streaming execution
        async for chunk in _bridge.stream_command(message, session_value):
            chunk_text = chunk or ""
            chunk_count += 1
            live_text += chunk_text
            
            # Build terminal output with tool execution log
            terminal_lines = [
                f"# Execution Log (Session: {session_value[:8]})",
                f"# Time: {round(time.monotonic() - start, 2)}s | Chunks: {chunk_count}",
                "",
                "## Output Stream:",
                live_text if live_text else "(waiting for output...)",
            ]
            terminal_output = "\n".join(terminal_lines)
            
            # Update metrics
            metrics = {
                "chunks": chunk_count,
                "chars": len(live_text),
                "sec": round(time.monotonic() - start, 2),
                "backend": _bridge.backend_label,
            }
            
            # PHASE 3: Streaming with typing cursor
            history[-1]["content"] = live_text + " ‚ñå"
            
            yield history, terminal_output, session_value, metrics, gr.update(visible=False)
            
    except Exception as e:
        # PHASE 4: Error state
        error_msg = f"‚ùå **Error**: {str(e)}"
        history[-1]["content"] = error_msg
        terminal_output += f"\n\n‚ùå ERROR: {str(e)}"
        yield history, terminal_output, session_value, _blank_metrics(), gr.update(visible=False)
        return

    # PHASE 5: Complete state with success indicator
    history[-1]["content"] = live_text  # Remove cursor
    
    # Add success indicator to terminal
    terminal_lines = [
        f"# Execution Log (Session: {session_value[:8]})",
        f"# Time: {round(time.monotonic() - start, 2)}s | Chunks: {chunk_count}",
        "",
        "## Output Stream:",
        live_text if live_text else "(no output)",
        "",
        '<div class="success-check">‚úì Execution complete</div>',
    ]
    terminal_output = "\n".join(terminal_lines)
    
    final_metrics = {
        "chunks": chunk_count,
        "chars": len(live_text),
        "sec": round(time.monotonic() - start, 2),
        "backend": _bridge.backend_label,
    }
    
    yield history, terminal_output, session_value, final_metrics, gr.update(visible=False)


def clear_session():
    return [], "", None, _blank_metrics(), gr.update(visible=True)


# --- UI CONSTRUCTION ---

def create_ui() -> gr.Blocks:
    """Build the Championship UI - Vercel/Linear inspired."""
    
    # Create theme and inject CSS
    heroic_theme = create_heroic_theme()

    with gr.Blocks(
        title="Qwen Dev CLI ¬∑ 27 MCP Tools ¬∑ Constitutional AI",
        theme=heroic_theme,
        css=CUSTOM_CSS  # Inject CSS as string
    ) as demo:
        
        # State Management
        session_state = gr.State(value=None)
        
        # === HEADER: Compact single-line ===
        with gr.Row(elem_id="header-row"):
            gr.Markdown(
                "**Qwen Dev CLI** ¬∑ 27 MCP Tools ¬∑ Constitutional AI-Powered Development",
                elem_id="header-title"
            )
        
        # === MAIN LAYOUT: 3-PANE ===
        with gr.Row(equal_height=False):
            
            # === LEFT: COMPACT SIDEBAR (250px) ===
            with gr.Column(scale=1, min_width=250, variant="panel"):
                gr.Markdown("**FILES**", elem_id="sidebar-title")
                
                # File Explorer - Compact (250px height max)
                file_explorer = gr.FileExplorer(
                    glob="**/*",
                    root_dir=str(PROJECT_ROOT),
                    height=250,
                    label="Workspace",
                    elem_id="file-explorer"
                )
                
                # Metrics - Compact JSON
                metrics_display = gr.JSON(
                    value=_blank_metrics(),
                    label="Telemetry",
                    elem_id="metrics-panel"
                )

            # === CENTER: CHAT + INPUT ===
            with gr.Column(scale=3, min_width=500):
                
                # HERO STATE - Minimal text-only
                with gr.Group(visible=True, elem_id="hero-welcome") as hero_group:
                    gr.Markdown(
                        "# Start coding with AI\n\n"
                        "Ask me to read files, run tests, refactor code, or fix bugs.",
                        elem_id="hero-header"
                    )
                    gr.Markdown("**Quick Start:**", elem_id="hero-quickstart-label")
                    with gr.Row():
                        ex_btn_1 = gr.Button(COMMAND_EXAMPLES[0][0], size="sm", variant="secondary", elem_classes=["example-pill"])
                        ex_btn_2 = gr.Button(COMMAND_EXAMPLES[1][0], size="sm", variant="secondary", elem_classes=["example-pill"])
                        ex_btn_3 = gr.Button(COMMAND_EXAMPLES[2][0], size="sm", variant="secondary", elem_classes=["example-pill"])
                
                # CHAT - Compact (400px)
                chatbot = gr.Chatbot(
                    label="Dev Session",
                    type="messages",
                    height=400,
                    show_copy_button=True,
                    avatar_images=(None, None),
                    render_markdown=True,
                    elem_id="main-chatbot"
                )
                
                # INPUT BAR - Clean & Minimal
                with gr.Row():
                    msg_input = gr.Textbox(
                        show_label=False,
                        placeholder="Instruct the agent (e.g., 'Run tests and fix errors')...",
                        container=False,
                        scale=5,
                        elem_id="command-input"
                    )
                    run_btn = gr.Button("Run", variant="primary", scale=0, min_width=80)

            # === RIGHT: TERMINAL + TOOLS ===
            with gr.Column(scale=2, min_width=300, variant="panel"):
                with gr.Tabs(elem_id="right-tabs"):
                    with gr.Tab("Terminal", elem_id="terminal-tab"):
                        # Shell output - Compact (15 lines)
                        shell_output = gr.Code(
                            language="shell",
                            label="Live Output",
                            interactive=False,
                            lines=15,
                            elem_id="shell-output"
                        )
                    
                    with gr.Tab("MCP Tools", elem_id="mcp-tab"):
                        # Real tools from registry
                        mcp_df = gr.Dataframe(
                            value=_get_mcp_tools_df(),
                            headers=["Category", "Tool", "Description"],
                            interactive=False,
                            elem_id="mcp-tools-table"
                        )
        
        # === FOOTER: Status strip ===
        with gr.Row(elem_id="footer-row"):
            status_text = gr.Markdown(
                f"Backend: {_bridge.backend_label} ¬∑ Tokens: 0 ¬∑ Cost: $0.00",
                elem_id="footer-status"
            )

        # === EVENT HANDLERS ===
        
        # Submit message
        msg_input.submit(
            fn=stream_conversation,
            inputs=[msg_input, chatbot, session_state],
            outputs=[chatbot, shell_output, session_state, metrics_display, hero_group]
        ).then(
            fn=lambda: "", outputs=[msg_input]
        )
        
        # Run button
        run_btn.click(
            fn=stream_conversation,
            inputs=[msg_input, chatbot, session_state],
            outputs=[chatbot, shell_output, session_state, metrics_display, hero_group]
        ).then(
            fn=lambda: "", outputs=[msg_input]
        )
        
        # Example buttons - populate input
        def set_example(text):
            return text
        
        ex_btn_1.click(fn=lambda: COMMAND_EXAMPLES[0][0], outputs=[msg_input])
        ex_btn_2.click(fn=lambda: COMMAND_EXAMPLES[1][0], outputs=[msg_input])
        ex_btn_3.click(fn=lambda: COMMAND_EXAMPLES[2][0], outputs=[msg_input])

    return demo


# --- LAUNCHER (Gradio 6.x Style) ---
if __name__ == "__main__":
    port = int(os.getenv("GRADIO_SERVER_PORT", "7861"))
    
    # Create the app
    demo = create_ui()
    
    print(f"üöÄ Launching Heroic UI on port {port}")
    
    # Launch with app-level settings
    demo.launch(
        server_name="0.0.0.0",
        server_port=port,
        share=False,
        show_error=True,
        ssr_mode=False # Disable SSR for now to avoid Node.js dependency issues
    )
